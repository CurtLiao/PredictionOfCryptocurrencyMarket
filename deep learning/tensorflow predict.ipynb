{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK</th>\n",
       "      <th>BID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LAST</th>\n",
       "      <th>LOW</th>\n",
       "      <th>MID</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6785.300</td>\n",
       "      <td>6785.200</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>6897.400</td>\n",
       "      <td>6785.30</td>\n",
       "      <td>6650.000</td>\n",
       "      <td>6785.250</td>\n",
       "      <td>26054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6698.400</td>\n",
       "      <td>6698.300</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>7189.000</td>\n",
       "      <td>6698.40</td>\n",
       "      <td>6611.000</td>\n",
       "      <td>6698.350</td>\n",
       "      <td>76309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6596.500</td>\n",
       "      <td>6591.400</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>6864.000</td>\n",
       "      <td>6595.60</td>\n",
       "      <td>6500.200</td>\n",
       "      <td>6593.950</td>\n",
       "      <td>41534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6780.000</td>\n",
       "      <td>6779.900</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>6938.000</td>\n",
       "      <td>6780.00</td>\n",
       "      <td>6564.900</td>\n",
       "      <td>6779.950</td>\n",
       "      <td>46048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6741.300</td>\n",
       "      <td>6740.600</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>7450.000</td>\n",
       "      <td>6741.30</td>\n",
       "      <td>6670.000</td>\n",
       "      <td>6740.950</td>\n",
       "      <td>53111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7394.200</td>\n",
       "      <td>7394.100</td>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>7509.700</td>\n",
       "      <td>7394.13</td>\n",
       "      <td>7007.400</td>\n",
       "      <td>7394.150</td>\n",
       "      <td>50882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7025.700</td>\n",
       "      <td>7025.600</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>7132.000</td>\n",
       "      <td>7025.60</td>\n",
       "      <td>6768.000</td>\n",
       "      <td>7025.650</td>\n",
       "      <td>43988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6806.100</td>\n",
       "      <td>6806.000</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>7035.100</td>\n",
       "      <td>6806.10</td>\n",
       "      <td>6425.100</td>\n",
       "      <td>6806.050</td>\n",
       "      <td>54592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6944.200</td>\n",
       "      <td>6944.100</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>7222.000</td>\n",
       "      <td>6944.10</td>\n",
       "      <td>6751.100</td>\n",
       "      <td>6944.150</td>\n",
       "      <td>68543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6774.600</td>\n",
       "      <td>6774.500</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>7269.000</td>\n",
       "      <td>6774.60</td>\n",
       "      <td>6533.000</td>\n",
       "      <td>6774.550</td>\n",
       "      <td>110807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7220.000</td>\n",
       "      <td>7219.900</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>7973.000</td>\n",
       "      <td>7219.90</td>\n",
       "      <td>6883.000</td>\n",
       "      <td>7219.950</td>\n",
       "      <td>73997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7960.000</td>\n",
       "      <td>7959.300</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>8120.200</td>\n",
       "      <td>7962.00</td>\n",
       "      <td>7702.100</td>\n",
       "      <td>7959.650</td>\n",
       "      <td>37966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7926.700</td>\n",
       "      <td>7925.800</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>8277.800</td>\n",
       "      <td>7926.50</td>\n",
       "      <td>7716.600</td>\n",
       "      <td>7926.250</td>\n",
       "      <td>49132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8187.900</td>\n",
       "      <td>8183.800</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>8516.900</td>\n",
       "      <td>8177.40</td>\n",
       "      <td>7835.900</td>\n",
       "      <td>8185.850</td>\n",
       "      <td>58065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8480.800</td>\n",
       "      <td>8479.900</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>8674.400</td>\n",
       "      <td>8481.00</td>\n",
       "      <td>8364.800</td>\n",
       "      <td>8480.350</td>\n",
       "      <td>30079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8643.800</td>\n",
       "      <td>8639.700</td>\n",
       "      <td>2018-03-24</td>\n",
       "      <td>9050.300</td>\n",
       "      <td>8639.70</td>\n",
       "      <td>8556.000</td>\n",
       "      <td>8641.750</td>\n",
       "      <td>44565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8690.900</td>\n",
       "      <td>8690.200</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>9095.920</td>\n",
       "      <td>8690.90</td>\n",
       "      <td>8450.000</td>\n",
       "      <td>8690.550</td>\n",
       "      <td>54383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8870.100</td>\n",
       "      <td>8870.000</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>9177.500</td>\n",
       "      <td>8870.00</td>\n",
       "      <td>8752.000</td>\n",
       "      <td>8870.050</td>\n",
       "      <td>42946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8932.000</td>\n",
       "      <td>8931.900</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>9040.000</td>\n",
       "      <td>8932.00</td>\n",
       "      <td>8305.100</td>\n",
       "      <td>8931.950</td>\n",
       "      <td>55419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8500.000</td>\n",
       "      <td>8499.900</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>8717.000</td>\n",
       "      <td>8505.00</td>\n",
       "      <td>8085.700</td>\n",
       "      <td>8499.950</td>\n",
       "      <td>74323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8149.100</td>\n",
       "      <td>8148.800</td>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>8300.000</td>\n",
       "      <td>8147.00</td>\n",
       "      <td>7240.000</td>\n",
       "      <td>8148.950</td>\n",
       "      <td>87116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7993.100</td>\n",
       "      <td>7993.000</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>8515.900</td>\n",
       "      <td>7993.00</td>\n",
       "      <td>7728.100</td>\n",
       "      <td>7993.050</td>\n",
       "      <td>50245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8488.300</td>\n",
       "      <td>8481.000</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>8604.500</td>\n",
       "      <td>8494.30</td>\n",
       "      <td>7902.000</td>\n",
       "      <td>8484.650</td>\n",
       "      <td>54272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8269.000</td>\n",
       "      <td>8268.900</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>8418.000</td>\n",
       "      <td>8267.70</td>\n",
       "      <td>7665.100</td>\n",
       "      <td>8268.950</td>\n",
       "      <td>83733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8175.100</td>\n",
       "      <td>8175.000</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>9439.600</td>\n",
       "      <td>8175.10</td>\n",
       "      <td>7916.000</td>\n",
       "      <td>8175.050</td>\n",
       "      <td>77582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9150.600</td>\n",
       "      <td>9150.500</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>9482.400</td>\n",
       "      <td>9150.60</td>\n",
       "      <td>8822.000</td>\n",
       "      <td>9150.550</td>\n",
       "      <td>62993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9098.500</td>\n",
       "      <td>9098.400</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>9900.000</td>\n",
       "      <td>9098.40</td>\n",
       "      <td>8770.000</td>\n",
       "      <td>9098.450</td>\n",
       "      <td>67217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9485.100</td>\n",
       "      <td>9482.100</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>9729.000</td>\n",
       "      <td>9485.20</td>\n",
       "      <td>8428.000</td>\n",
       "      <td>9483.600</td>\n",
       "      <td>70288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8807.800</td>\n",
       "      <td>8807.700</td>\n",
       "      <td>2018-03-10</td>\n",
       "      <td>9506.400</td>\n",
       "      <td>8807.70</td>\n",
       "      <td>8670.900</td>\n",
       "      <td>8807.750</td>\n",
       "      <td>52902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9303.000</td>\n",
       "      <td>9302.400</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>9428.000</td>\n",
       "      <td>9303.00</td>\n",
       "      <td>8342.000</td>\n",
       "      <td>9302.700</td>\n",
       "      <td>98498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>446.970</td>\n",
       "      <td>446.400</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>451.400</td>\n",
       "      <td>446.97</td>\n",
       "      <td>442.510</td>\n",
       "      <td>446.685</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>447.400</td>\n",
       "      <td>447.000</td>\n",
       "      <td>2014-05-14</td>\n",
       "      <td>448.000</td>\n",
       "      <td>447.00</td>\n",
       "      <td>437.810</td>\n",
       "      <td>447.200</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>439.000</td>\n",
       "      <td>437.810</td>\n",
       "      <td>2014-05-13</td>\n",
       "      <td>442.000</td>\n",
       "      <td>437.82</td>\n",
       "      <td>434.010</td>\n",
       "      <td>438.405</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>439.410</td>\n",
       "      <td>439.400</td>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>442.000</td>\n",
       "      <td>439.41</td>\n",
       "      <td>431.800</td>\n",
       "      <td>439.405</td>\n",
       "      <td>3454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>436.850</td>\n",
       "      <td>436.810</td>\n",
       "      <td>2014-05-11</td>\n",
       "      <td>459.650</td>\n",
       "      <td>436.85</td>\n",
       "      <td>430.000</td>\n",
       "      <td>436.830</td>\n",
       "      <td>11882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>455.200</td>\n",
       "      <td>455.000</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>457.000</td>\n",
       "      <td>455.00</td>\n",
       "      <td>448.200</td>\n",
       "      <td>455.100</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>443.490</td>\n",
       "      <td>442.000</td>\n",
       "      <td>2014-05-08</td>\n",
       "      <td>450.590</td>\n",
       "      <td>442.00</td>\n",
       "      <td>438.600</td>\n",
       "      <td>442.745</td>\n",
       "      <td>4046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>446.000</td>\n",
       "      <td>445.720</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>453.600</td>\n",
       "      <td>446.00</td>\n",
       "      <td>424.249</td>\n",
       "      <td>445.860</td>\n",
       "      <td>10468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>430.900</td>\n",
       "      <td>429.500</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>435.390</td>\n",
       "      <td>430.90</td>\n",
       "      <td>419.400</td>\n",
       "      <td>430.200</td>\n",
       "      <td>6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>432.237</td>\n",
       "      <td>430.750</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>444.400</td>\n",
       "      <td>430.75</td>\n",
       "      <td>425.600</td>\n",
       "      <td>431.493</td>\n",
       "      <td>5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>436.900</td>\n",
       "      <td>436.200</td>\n",
       "      <td>2014-05-04</td>\n",
       "      <td>441.950</td>\n",
       "      <td>436.40</td>\n",
       "      <td>429.000</td>\n",
       "      <td>436.550</td>\n",
       "      <td>4157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>441.380</td>\n",
       "      <td>440.300</td>\n",
       "      <td>2014-05-03</td>\n",
       "      <td>455.000</td>\n",
       "      <td>441.30</td>\n",
       "      <td>430.000</td>\n",
       "      <td>440.840</td>\n",
       "      <td>7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>449.850</td>\n",
       "      <td>449.460</td>\n",
       "      <td>2014-05-02</td>\n",
       "      <td>461.670</td>\n",
       "      <td>449.85</td>\n",
       "      <td>443.000</td>\n",
       "      <td>449.655</td>\n",
       "      <td>3298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>460.090</td>\n",
       "      <td>459.100</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>463.530</td>\n",
       "      <td>460.10</td>\n",
       "      <td>446.990</td>\n",
       "      <td>459.595</td>\n",
       "      <td>5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>449.370</td>\n",
       "      <td>449.360</td>\n",
       "      <td>2014-04-30</td>\n",
       "      <td>453.600</td>\n",
       "      <td>449.37</td>\n",
       "      <td>432.000</td>\n",
       "      <td>449.365</td>\n",
       "      <td>6877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>447.000</td>\n",
       "      <td>445.550</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>454.000</td>\n",
       "      <td>445.54</td>\n",
       "      <td>434.000</td>\n",
       "      <td>446.275</td>\n",
       "      <td>8521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>445.500</td>\n",
       "      <td>445.400</td>\n",
       "      <td>2014-04-28</td>\n",
       "      <td>450.000</td>\n",
       "      <td>445.40</td>\n",
       "      <td>423.110</td>\n",
       "      <td>445.450</td>\n",
       "      <td>16467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>445.910</td>\n",
       "      <td>445.500</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>465.600</td>\n",
       "      <td>445.00</td>\n",
       "      <td>440.000</td>\n",
       "      <td>445.705</td>\n",
       "      <td>5959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>459.000</td>\n",
       "      <td>457.600</td>\n",
       "      <td>2014-04-26</td>\n",
       "      <td>469.190</td>\n",
       "      <td>457.60</td>\n",
       "      <td>449.800</td>\n",
       "      <td>458.300</td>\n",
       "      <td>8578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>465.955</td>\n",
       "      <td>463.790</td>\n",
       "      <td>2014-04-25</td>\n",
       "      <td>504.960</td>\n",
       "      <td>463.79</td>\n",
       "      <td>441.300</td>\n",
       "      <td>464.872</td>\n",
       "      <td>30376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>497.980</td>\n",
       "      <td>497.000</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>498.840</td>\n",
       "      <td>497.98</td>\n",
       "      <td>480.160</td>\n",
       "      <td>497.490</td>\n",
       "      <td>4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>491.599</td>\n",
       "      <td>490.040</td>\n",
       "      <td>2014-04-23</td>\n",
       "      <td>496.000</td>\n",
       "      <td>490.03</td>\n",
       "      <td>482.880</td>\n",
       "      <td>490.819</td>\n",
       "      <td>4716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>491.390</td>\n",
       "      <td>491.210</td>\n",
       "      <td>2014-04-22</td>\n",
       "      <td>506.000</td>\n",
       "      <td>491.20</td>\n",
       "      <td>488.800</td>\n",
       "      <td>491.300</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>497.180</td>\n",
       "      <td>497.000</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>515.646</td>\n",
       "      <td>497.00</td>\n",
       "      <td>485.000</td>\n",
       "      <td>497.090</td>\n",
       "      <td>8132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>501.420</td>\n",
       "      <td>500.072</td>\n",
       "      <td>2014-04-20</td>\n",
       "      <td>517.995</td>\n",
       "      <td>501.44</td>\n",
       "      <td>492.200</td>\n",
       "      <td>500.746</td>\n",
       "      <td>4921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>507.490</td>\n",
       "      <td>502.531</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>513.990</td>\n",
       "      <td>507.50</td>\n",
       "      <td>473.830</td>\n",
       "      <td>505.011</td>\n",
       "      <td>8963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>484.790</td>\n",
       "      <td>482.750</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>509.000</td>\n",
       "      <td>482.75</td>\n",
       "      <td>474.250</td>\n",
       "      <td>483.770</td>\n",
       "      <td>10458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>508.000</td>\n",
       "      <td>506.040</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>538.500</td>\n",
       "      <td>508.00</td>\n",
       "      <td>486.100</td>\n",
       "      <td>507.020</td>\n",
       "      <td>20709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>538.000</td>\n",
       "      <td>537.000</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>547.000</td>\n",
       "      <td>538.00</td>\n",
       "      <td>495.000</td>\n",
       "      <td>537.500</td>\n",
       "      <td>29633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>504.970</td>\n",
       "      <td>503.500</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>513.900</td>\n",
       "      <td>505.00</td>\n",
       "      <td>452.000</td>\n",
       "      <td>504.235</td>\n",
       "      <td>21013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1422 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ASK       BID       DATE      HIGH     LAST       LOW       MID  \\\n",
       "0     6785.300  6785.200 2018-04-10  6897.400  6785.30  6650.000  6785.250   \n",
       "1     6698.400  6698.300 2018-04-09  7189.000  6698.40  6611.000  6698.350   \n",
       "2     6596.500  6591.400 2018-04-06  6864.000  6595.60  6500.200  6593.950   \n",
       "3     6780.000  6779.900 2018-04-05  6938.000  6780.00  6564.900  6779.950   \n",
       "4     6741.300  6740.600 2018-04-04  7450.000  6741.30  6670.000  6740.950   \n",
       "5     7394.200  7394.100 2018-04-03  7509.700  7394.13  7007.400  7394.150   \n",
       "6     7025.700  7025.600 2018-04-02  7132.000  7025.60  6768.000  7025.650   \n",
       "7     6806.100  6806.000 2018-04-01  7035.100  6806.10  6425.100  6806.050   \n",
       "8     6944.200  6944.100 2018-03-31  7222.000  6944.10  6751.100  6944.150   \n",
       "9     6774.600  6774.500 2018-03-30  7269.000  6774.60  6533.000  6774.550   \n",
       "10    7220.000  7219.900 2018-03-29  7973.000  7219.90  6883.000  7219.950   \n",
       "11    7960.000  7959.300 2018-03-28  8120.200  7962.00  7702.100  7959.650   \n",
       "12    7926.700  7925.800 2018-03-27  8277.800  7926.50  7716.600  7926.250   \n",
       "13    8187.900  8183.800 2018-03-26  8516.900  8177.40  7835.900  8185.850   \n",
       "14    8480.800  8479.900 2018-03-25  8674.400  8481.00  8364.800  8480.350   \n",
       "15    8643.800  8639.700 2018-03-24  9050.300  8639.70  8556.000  8641.750   \n",
       "16    8690.900  8690.200 2018-03-22  9095.920  8690.90  8450.000  8690.550   \n",
       "17    8870.100  8870.000 2018-03-21  9177.500  8870.00  8752.000  8870.050   \n",
       "18    8932.000  8931.900 2018-03-20  9040.000  8932.00  8305.100  8931.950   \n",
       "19    8500.000  8499.900 2018-03-19  8717.000  8505.00  8085.700  8499.950   \n",
       "20    8149.100  8148.800 2018-03-18  8300.000  8147.00  7240.000  8148.950   \n",
       "21    7993.100  7993.000 2018-03-17  8515.900  7993.00  7728.100  7993.050   \n",
       "22    8488.300  8481.000 2018-03-16  8604.500  8494.30  7902.000  8484.650   \n",
       "23    8269.000  8268.900 2018-03-15  8418.000  8267.70  7665.100  8268.950   \n",
       "24    8175.100  8175.000 2018-03-14  9439.600  8175.10  7916.000  8175.050   \n",
       "25    9150.600  9150.500 2018-03-13  9482.400  9150.60  8822.000  9150.550   \n",
       "26    9098.500  9098.400 2018-03-12  9900.000  9098.40  8770.000  9098.450   \n",
       "27    9485.100  9482.100 2018-03-11  9729.000  9485.20  8428.000  9483.600   \n",
       "28    8807.800  8807.700 2018-03-10  9506.400  8807.70  8670.900  8807.750   \n",
       "29    9303.000  9302.400 2018-03-09  9428.000  9303.00  8342.000  9302.700   \n",
       "...        ...       ...        ...       ...      ...       ...       ...   \n",
       "1392   446.970   446.400 2014-05-15   451.400   446.97   442.510   446.685   \n",
       "1393   447.400   447.000 2014-05-14   448.000   447.00   437.810   447.200   \n",
       "1394   439.000   437.810 2014-05-13   442.000   437.82   434.010   438.405   \n",
       "1395   439.410   439.400 2014-05-12   442.000   439.41   431.800   439.405   \n",
       "1396   436.850   436.810 2014-05-11   459.650   436.85   430.000   436.830   \n",
       "1397   455.200   455.000 2014-05-10   457.000   455.00   448.200   455.100   \n",
       "1398   443.490   442.000 2014-05-08   450.590   442.00   438.600   442.745   \n",
       "1399   446.000   445.720 2014-05-07   453.600   446.00   424.249   445.860   \n",
       "1400   430.900   429.500 2014-05-06   435.390   430.90   419.400   430.200   \n",
       "1401   432.237   430.750 2014-05-05   444.400   430.75   425.600   431.493   \n",
       "1402   436.900   436.200 2014-05-04   441.950   436.40   429.000   436.550   \n",
       "1403   441.380   440.300 2014-05-03   455.000   441.30   430.000   440.840   \n",
       "1404   449.850   449.460 2014-05-02   461.670   449.85   443.000   449.655   \n",
       "1405   460.090   459.100 2014-05-01   463.530   460.10   446.990   459.595   \n",
       "1406   449.370   449.360 2014-04-30   453.600   449.37   432.000   449.365   \n",
       "1407   447.000   445.550 2014-04-29   454.000   445.54   434.000   446.275   \n",
       "1408   445.500   445.400 2014-04-28   450.000   445.40   423.110   445.450   \n",
       "1409   445.910   445.500 2014-04-27   465.600   445.00   440.000   445.705   \n",
       "1410   459.000   457.600 2014-04-26   469.190   457.60   449.800   458.300   \n",
       "1411   465.955   463.790 2014-04-25   504.960   463.79   441.300   464.872   \n",
       "1412   497.980   497.000 2014-04-24   498.840   497.98   480.160   497.490   \n",
       "1413   491.599   490.040 2014-04-23   496.000   490.03   482.880   490.819   \n",
       "1414   491.390   491.210 2014-04-22   506.000   491.20   488.800   491.300   \n",
       "1415   497.180   497.000 2014-04-21   515.646   497.00   485.000   497.090   \n",
       "1416   501.420   500.072 2014-04-20   517.995   501.44   492.200   500.746   \n",
       "1417   507.490   502.531 2014-04-19   513.990   507.50   473.830   505.011   \n",
       "1418   484.790   482.750 2014-04-18   509.000   482.75   474.250   483.770   \n",
       "1419   508.000   506.040 2014-04-17   538.500   508.00   486.100   507.020   \n",
       "1420   538.000   537.000 2014-04-16   547.000   538.00   495.000   537.500   \n",
       "1421   504.970   503.500 2014-04-15   513.900   505.00   452.000   504.235   \n",
       "\n",
       "      VOLUME  \n",
       "0      26054  \n",
       "1      76309  \n",
       "2      41534  \n",
       "3      46048  \n",
       "4      53111  \n",
       "5      50882  \n",
       "6      43988  \n",
       "7      54592  \n",
       "8      68543  \n",
       "9     110807  \n",
       "10     73997  \n",
       "11     37966  \n",
       "12     49132  \n",
       "13     58065  \n",
       "14     30079  \n",
       "15     44565  \n",
       "16     54383  \n",
       "17     42946  \n",
       "18     55419  \n",
       "19     74323  \n",
       "20     87116  \n",
       "21     50245  \n",
       "22     54272  \n",
       "23     83733  \n",
       "24     77582  \n",
       "25     62993  \n",
       "26     67217  \n",
       "27     70288  \n",
       "28     52902  \n",
       "29     98498  \n",
       "...      ...  \n",
       "1392    1892  \n",
       "1393    3086  \n",
       "1394    1913  \n",
       "1395    3454  \n",
       "1396   11882  \n",
       "1397    2438  \n",
       "1398    4046  \n",
       "1399   10468  \n",
       "1400    6980  \n",
       "1401    5940  \n",
       "1402    4157  \n",
       "1403    7611  \n",
       "1404    3298  \n",
       "1405    5339  \n",
       "1406    6877  \n",
       "1407    8521  \n",
       "1408   16467  \n",
       "1409    5959  \n",
       "1410    8578  \n",
       "1411   30376  \n",
       "1412    4316  \n",
       "1413    4716  \n",
       "1414    3105  \n",
       "1415    8132  \n",
       "1416    4921  \n",
       "1417    8963  \n",
       "1418   10458  \n",
       "1419   20709  \n",
       "1420   29633  \n",
       "1421   21013  \n",
       "\n",
       "[1422 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pymysql as pms\n",
    "\n",
    "\n",
    "db = pms.connect(\"140.118.126.136\", \"123\", \"1234567890\", \"test\",cursorclass=pms.cursors.DictCursor)\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"select * from btc_usd order by DATE DESC\")\n",
    "result = cursor.fetchall()\n",
    "btc_data = pd.DataFrame(result)\n",
    "btc_data = btc_data.assign(DATE=pd.to_datetime(btc_data['DATE']))\n",
    "btc_data['VOLUME'] = (pd.to_numeric(btc_data['VOLUME'], errors='coerce').fillna(0))\n",
    "btc_data['VOLUME'] = btc_data['VOLUME'].astype('int64')\n",
    "btc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def some fun tp process data\n",
    "def add_newcol(btc_data): #新增closeoffhigh和volatolity欄位，增加模型訓練的準確度\n",
    "    market_info = btc_data[btc_data['DATE']>='2017-01-01'] #將資料只獲取從2017-01-01之後的內容，存到 market_info\n",
    "    kwargs = { 'CLOSE_OFF_HIGH': lambda x: 2*(x['HIGH'] - x['LAST']) / (x['HIGH'] - x['LOW']) - 1, # 1:收盤接近最低價  -1:收盤接近最高價  \n",
    "          'VOLATILITY': lambda x: (x['HIGH'] - x['LOW']) / (x['MID'])}  #越趨近0越看好\n",
    "    market_info = market_info.assign(**kwargs)\n",
    "    return market_info\n",
    "def create_model_data(btc_data):#選取待會訓練模型所需要的資料\n",
    "    model_data = btc_data[[\"DATE\"]+[\"LAST\"]+[\"VOLUME\"]+[\"CLOSE_OFF_HIGH\"]+[\"VOLATILITY\"]]\n",
    "    model_data = model_data.sort_values(by='DATE')\n",
    "    return model_data\n",
    "def create_input_data(data,window_len):#決定訓練時以多少天的大小作訓練(window_len)，以每個為window_len大小的array，作為待會訓練模型的input\n",
    "    norm_cols = ['LAST','VOLUME']\n",
    "    inputs = [] #將Close,Volume以每筆的第一個資料來作正規化，讓值介於-1,1之間\n",
    "    for i in range(len(data)-window_len):\n",
    "        temp_set = data[i:(i+window_len)].copy()\n",
    "        for col in norm_cols:\n",
    "            temp_set.loc[:, col] = temp_set[col]/temp_set[col].iloc[0] - 1 #以window中的第一個為基準將\"volume\"與\"last\"做正規化\n",
    "        inputs.append(temp_set)\n",
    "    return inputs\n",
    "def create_output_data(data,window_len):#模型的輸出\n",
    "    return (data['LAST'][window_len:].values / data['LAST'][:-window_len].values) - 1\n",
    "def data_to_np(data):#原本資料的型態為dataframe，這裡將型態轉為numpy array，模型的資料是以這種型態為主\n",
    "    data = [np.array(datas)for datas in data]\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK</th>\n",
       "      <th>BID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LAST</th>\n",
       "      <th>LOW</th>\n",
       "      <th>MID</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>VOLATILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6785.3</td>\n",
       "      <td>6785.2</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>6897.4</td>\n",
       "      <td>6785.3</td>\n",
       "      <td>6650.0</td>\n",
       "      <td>6785.25</td>\n",
       "      <td>26054</td>\n",
       "      <td>-0.093775</td>\n",
       "      <td>0.036461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6698.4</td>\n",
       "      <td>6698.3</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>7189.0</td>\n",
       "      <td>6698.4</td>\n",
       "      <td>6611.0</td>\n",
       "      <td>6698.35</td>\n",
       "      <td>76309</td>\n",
       "      <td>0.697578</td>\n",
       "      <td>0.086290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6596.5</td>\n",
       "      <td>6591.4</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>6864.0</td>\n",
       "      <td>6595.6</td>\n",
       "      <td>6500.2</td>\n",
       "      <td>6593.95</td>\n",
       "      <td>41534</td>\n",
       "      <td>0.475536</td>\n",
       "      <td>0.055172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6780.0</td>\n",
       "      <td>6779.9</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>6938.0</td>\n",
       "      <td>6780.0</td>\n",
       "      <td>6564.9</td>\n",
       "      <td>6779.95</td>\n",
       "      <td>46048</td>\n",
       "      <td>-0.153042</td>\n",
       "      <td>0.055030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6741.3</td>\n",
       "      <td>6740.6</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>6741.3</td>\n",
       "      <td>6670.0</td>\n",
       "      <td>6740.95</td>\n",
       "      <td>53111</td>\n",
       "      <td>0.817179</td>\n",
       "      <td>0.115711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ASK     BID       DATE    HIGH    LAST     LOW      MID  VOLUME  \\\n",
       "0  6785.3  6785.2 2018-04-10  6897.4  6785.3  6650.0  6785.25   26054   \n",
       "1  6698.4  6698.3 2018-04-09  7189.0  6698.4  6611.0  6698.35   76309   \n",
       "2  6596.5  6591.4 2018-04-06  6864.0  6595.6  6500.2  6593.95   41534   \n",
       "3  6780.0  6779.9 2018-04-05  6938.0  6780.0  6564.9  6779.95   46048   \n",
       "4  6741.3  6740.6 2018-04-04  7450.0  6741.3  6670.0  6740.95   53111   \n",
       "\n",
       "   CLOSE_OFF_HIGH  VOLATILITY  \n",
       "0       -0.093775    0.036461  \n",
       "1        0.697578    0.086290  \n",
       "2        0.475536    0.055172  \n",
       "3       -0.153042    0.055030  \n",
       "4        0.817179    0.115711  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_info = add_newcol(btc_data)\n",
    "market_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LAST</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>VOLATILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>6741.3</td>\n",
       "      <td>53111</td>\n",
       "      <td>0.817179</td>\n",
       "      <td>0.115711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>6780.0</td>\n",
       "      <td>46048</td>\n",
       "      <td>-0.153042</td>\n",
       "      <td>0.055030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>6595.6</td>\n",
       "      <td>41534</td>\n",
       "      <td>0.475536</td>\n",
       "      <td>0.055172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>6698.4</td>\n",
       "      <td>76309</td>\n",
       "      <td>0.697578</td>\n",
       "      <td>0.086290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>6785.3</td>\n",
       "      <td>26054</td>\n",
       "      <td>-0.093775</td>\n",
       "      <td>0.036461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE    LAST  VOLUME  CLOSE_OFF_HIGH  VOLATILITY\n",
       "4 2018-04-04  6741.3   53111        0.817179    0.115711\n",
       "3 2018-04-05  6780.0   46048       -0.153042    0.055030\n",
       "2 2018-04-06  6595.6   41534        0.475536    0.055172\n",
       "1 2018-04-09  6698.4   76309        0.697578    0.086290\n",
       "0 2018-04-10  6785.3   26054       -0.093775    0.036461"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data= create_model_data(market_info)\n",
    "model_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LAST</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>VOLATILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>13769.0</td>\n",
       "      <td>43269</td>\n",
       "      <td>-0.568493</td>\n",
       "      <td>0.148509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>13375.0</td>\n",
       "      <td>29564</td>\n",
       "      <td>-0.071685</td>\n",
       "      <td>0.083464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>14723.1</td>\n",
       "      <td>56195</td>\n",
       "      <td>-0.425582</td>\n",
       "      <td>0.183826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>15134.0</td>\n",
       "      <td>38358</td>\n",
       "      <td>-0.365202</td>\n",
       "      <td>0.061305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>15175.0</td>\n",
       "      <td>46460</td>\n",
       "      <td>-0.637058</td>\n",
       "      <td>0.089802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE     LAST  VOLUME  CLOSE_OFF_HIGH  VOLATILITY\n",
       "96 2018-01-01  13769.0   43269       -0.568493    0.148509\n",
       "95 2018-01-02  13375.0   29564       -0.071685    0.083464\n",
       "94 2018-01-03  14723.1   56195       -0.425582    0.183826\n",
       "93 2018-01-04  15134.0   38358       -0.365202    0.061305\n",
       "92 2018-01-05  15175.0   46460       -0.637058    0.089802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date = '2018-01-01' #將training_set,test_set從這個日期做劃分\n",
    "training_set, test_set = model_data[model_data['DATE']<split_date], model_data[model_data['DATE']>=split_date]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = training_set.drop('DATE', 1) #將Date的欄位刪掉，因為之後不會需要用到它，因為後面要將形式轉為np array，故只留數值的部分\n",
    "test_set = test_set.drop('DATE', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.06296231]]\n",
      "\n",
      " [[-0.21984708]]\n",
      "\n",
      " [[-0.21040706]]\n",
      "\n",
      " [[-0.20306358]]\n",
      "\n",
      " [[-0.28409091]]\n",
      "\n",
      " [[-0.18204106]]\n",
      "\n",
      " [[-0.07612688]]\n",
      "\n",
      " [[-0.00452593]]\n",
      "\n",
      " [[-0.03030899]]\n",
      "\n",
      " [[-0.00160574]]\n",
      "\n",
      " [[-0.01060999]]\n",
      "\n",
      " [[ 0.18530966]]\n",
      "\n",
      " [[ 0.14749252]]\n",
      "\n",
      " [[ 0.09522255]]\n",
      "\n",
      " [[ 0.08653552]]\n",
      "\n",
      " [[ 0.08846894]]\n",
      "\n",
      " [[ 0.10272256]]\n",
      "\n",
      " [[ 0.01405989]]\n",
      "\n",
      " [[ 0.03523093]]\n",
      "\n",
      " [[ 0.01218998]]\n",
      "\n",
      " [[ 0.02367934]]\n",
      "\n",
      " [[ 0.04564836]]\n",
      "\n",
      " [[ 0.06473823]]\n",
      "\n",
      " [[ 0.1114913 ]]\n",
      "\n",
      " [[ 0.14716002]]\n",
      "\n",
      " [[ 0.15419488]]\n",
      "\n",
      " [[ 0.09966462]]\n",
      "\n",
      " [[ 0.11552307]]\n",
      "\n",
      " [[ 0.14429592]]\n",
      "\n",
      " [[ 0.14941647]]\n",
      "\n",
      " [[ 0.07372242]]\n",
      "\n",
      " [[ 0.02772718]]\n",
      "\n",
      " [[ 0.01675614]]\n",
      "\n",
      " [[-0.01092354]]\n",
      "\n",
      " [[-0.0200413 ]]\n",
      "\n",
      " [[-0.01726312]]\n",
      "\n",
      " [[ 0.00735148]]\n",
      "\n",
      " [[ 0.0155486 ]]\n",
      "\n",
      " [[ 0.0045623 ]]\n",
      "\n",
      " [[ 0.01039184]]\n",
      "\n",
      " [[ 0.07229515]]\n",
      "\n",
      " [[ 0.09860119]]\n",
      "\n",
      " [[ 0.1296    ]]\n",
      "\n",
      " [[ 0.1311245 ]]\n",
      "\n",
      " [[ 0.19485811]]\n",
      "\n",
      " [[ 0.16964374]]\n",
      "\n",
      " [[ 0.13708087]]\n",
      "\n",
      " [[ 0.13500241]]\n",
      "\n",
      " [[ 0.1315167 ]]\n",
      "\n",
      " [[ 0.12200415]]\n",
      "\n",
      " [[ 0.16909676]]\n",
      "\n",
      " [[ 0.15262627]]\n",
      "\n",
      " [[ 0.14173159]]\n",
      "\n",
      " [[ 0.12462276]]\n",
      "\n",
      " [[ 0.07365415]]\n",
      "\n",
      " [[ 0.07931151]]\n",
      "\n",
      " [[ 0.0687771 ]]\n",
      "\n",
      " [[-0.02434886]]\n",
      "\n",
      " [[-0.00468267]]\n",
      "\n",
      " [[-0.06366159]]\n",
      "\n",
      " [[-0.05077745]]\n",
      "\n",
      " [[-0.02624463]]\n",
      "\n",
      " [[-0.19143987]]\n",
      "\n",
      " [[-0.11886346]]\n",
      "\n",
      " [[-0.19477472]]\n",
      "\n",
      " [[-0.19824891]]\n",
      "\n",
      " [[-0.23915443]]\n",
      "\n",
      " [[-0.16515652]]\n",
      "\n",
      " [[-0.19650508]]\n",
      "\n",
      " [[-0.06969643]]\n",
      "\n",
      " [[-0.11057077]]\n",
      "\n",
      " [[-0.15264619]]\n",
      "\n",
      " [[-0.00949367]]\n",
      "\n",
      " [[-0.03170906]]\n",
      "\n",
      " [[ 0.05313775]]\n",
      "\n",
      " [[ 0.08170827]]\n",
      "\n",
      " [[ 0.23188174]]\n",
      "\n",
      " [[ 0.1831429 ]]\n",
      "\n",
      " [[ 0.17795901]]\n",
      "\n",
      " [[ 0.15746283]]\n",
      "\n",
      " [[ 0.14263789]]\n",
      "\n",
      " [[ 0.14216867]]\n",
      "\n",
      " [[ 0.17920418]]\n",
      "\n",
      " [[ 0.12710453]]\n",
      "\n",
      " [[ 0.14233004]]\n",
      "\n",
      " [[ 0.10492158]]\n",
      "\n",
      " [[ 0.02943723]]\n",
      "\n",
      " [[ 0.06329783]]\n",
      "\n",
      " [[ 0.06328777]]\n",
      "\n",
      " [[ 0.01351239]]\n",
      "\n",
      " [[ 0.03962391]]\n",
      "\n",
      " [[ 0.06936709]]\n",
      "\n",
      " [[ 0.0410509 ]]\n",
      "\n",
      " [[ 0.0685325 ]]\n",
      "\n",
      " [[ 0.06774871]]\n",
      "\n",
      " [[ 0.09561103]]\n",
      "\n",
      " [[ 0.131455  ]]\n",
      "\n",
      " [[ 0.11326379]]\n",
      "\n",
      " [[ 0.14366809]]\n",
      "\n",
      " [[ 0.15546046]]\n",
      "\n",
      " [[ 0.16731266]]\n",
      "\n",
      " [[ 0.10392992]]\n",
      "\n",
      " [[ 0.12318612]]\n",
      "\n",
      " [[ 0.10738152]]\n",
      "\n",
      " [[ 0.15525977]]\n",
      "\n",
      " [[ 0.15390916]]\n",
      "\n",
      " [[ 0.19898907]]\n",
      "\n",
      " [[ 0.17975606]]\n",
      "\n",
      " [[ 0.14722628]]\n",
      "\n",
      " [[ 0.13511396]]\n",
      "\n",
      " [[ 0.12313226]]\n",
      "\n",
      " [[ 0.2145257 ]]\n",
      "\n",
      " [[ 0.24210083]]\n",
      "\n",
      " [[ 0.23465353]]\n",
      "\n",
      " [[ 0.21641791]]\n",
      "\n",
      " [[ 0.14215655]]\n",
      "\n",
      " [[ 0.12461252]]\n",
      "\n",
      " [[ 0.14461325]]\n",
      "\n",
      " [[ 0.13367691]]\n",
      "\n",
      " [[ 0.11796449]]\n",
      "\n",
      " [[ 0.1547795 ]]\n",
      "\n",
      " [[ 0.14543849]]\n",
      "\n",
      " [[ 0.11362352]]\n",
      "\n",
      " [[ 0.16179775]]\n",
      "\n",
      " [[ 0.09670649]]\n",
      "\n",
      " [[ 0.11971751]]\n",
      "\n",
      " [[ 0.22822492]]\n",
      "\n",
      " [[ 0.31056893]]\n",
      "\n",
      " [[ 0.33404422]]\n",
      "\n",
      " [[ 0.18605826]]\n",
      "\n",
      " [[ 0.04000213]]\n",
      "\n",
      " [[ 0.04465341]]\n",
      "\n",
      " [[ 0.11340102]]\n",
      "\n",
      " [[ 0.01837524]]\n",
      "\n",
      " [[ 0.07738358]]\n",
      "\n",
      " [[ 0.15434684]]\n",
      "\n",
      " [[ 0.07271095]]\n",
      "\n",
      " [[ 0.0410153 ]]\n",
      "\n",
      " [[ 0.04173328]]\n",
      "\n",
      " [[ 0.23931005]]\n",
      "\n",
      " [[ 0.45068978]]\n",
      "\n",
      " [[ 0.3156911 ]]\n",
      "\n",
      " [[ 0.26543266]]\n",
      "\n",
      " [[ 0.33361823]]\n",
      "\n",
      " [[ 0.28179085]]\n",
      "\n",
      " [[ 0.28359122]]\n",
      "\n",
      " [[ 0.06435146]]\n",
      "\n",
      " [[ 0.08227031]]\n",
      "\n",
      " [[-0.04119215]]\n",
      "\n",
      " [[-0.08923942]]\n",
      "\n",
      " [[-0.14317531]]\n",
      "\n",
      " [[-0.01674892]]\n",
      "\n",
      " [[-0.10682375]]\n",
      "\n",
      " [[-0.08566546]]\n",
      "\n",
      " [[-0.02380699]]\n",
      "\n",
      " [[-0.11424777]]\n",
      "\n",
      " [[ 0.05157638]]\n",
      "\n",
      " [[ 0.00414025]]\n",
      "\n",
      " [[ 0.04675259]]\n",
      "\n",
      " [[ 0.03228241]]\n",
      "\n",
      " [[-0.01080992]]\n",
      "\n",
      " [[-0.05110266]]\n",
      "\n",
      " [[ 0.01314993]]\n",
      "\n",
      " [[-0.03025701]]\n",
      "\n",
      " [[-0.11695119]]\n",
      "\n",
      " [[-0.10422514]]\n",
      "\n",
      " [[-0.0888972 ]]\n",
      "\n",
      " [[-0.05259834]]\n",
      "\n",
      " [[ 0.03046033]]\n",
      "\n",
      " [[ 0.05645358]]\n",
      "\n",
      " [[ 0.08342023]]\n",
      "\n",
      " [[-0.01674948]]\n",
      "\n",
      " [[ 0.01182466]]\n",
      "\n",
      " [[ 0.00265028]]\n",
      "\n",
      " [[-0.04723825]]\n",
      "\n",
      " [[-0.00618026]]\n",
      "\n",
      " [[-0.02999344]]\n",
      "\n",
      " [[-0.08421878]]\n",
      "\n",
      " [[-0.13975555]]\n",
      "\n",
      " [[-0.21770721]]\n",
      "\n",
      " [[-0.24927815]]\n",
      "\n",
      " [[-0.10550982]]\n",
      "\n",
      " [[-0.09687574]]\n",
      "\n",
      " [[-0.09756098]]\n",
      "\n",
      " [[ 0.23081249]]\n",
      "\n",
      " [[ 0.16514078]]\n",
      "\n",
      " [[ 0.19961085]]\n",
      "\n",
      " [[ 0.16787259]]\n",
      "\n",
      " [[ 0.25851112]]\n",
      "\n",
      " [[ 0.24925058]]\n",
      "\n",
      " [[ 0.28769231]]\n",
      "\n",
      " [[ 0.22078455]]\n",
      "\n",
      " [[ 0.21449111]]\n",
      "\n",
      " [[ 0.19779878]]\n",
      "\n",
      " [[-0.04038806]]\n",
      "\n",
      " [[ 0.05559674]]\n",
      "\n",
      " [[-0.04583921]]\n",
      "\n",
      " [[-0.0141506 ]]\n",
      "\n",
      " [[ 0.0116862 ]]\n",
      "\n",
      " [[ 0.12269384]]\n",
      "\n",
      " [[ 0.28821187]]\n",
      "\n",
      " [[ 0.2129875 ]]\n",
      "\n",
      " [[ 0.21542601]]\n",
      "\n",
      " [[ 0.27851056]]\n",
      "\n",
      " [[ 0.2059707 ]]\n",
      "\n",
      " [[ 0.20280899]]\n",
      "\n",
      " [[ 0.35373245]]\n",
      "\n",
      " [[ 0.42592593]]\n",
      "\n",
      " [[ 0.46493636]]\n",
      "\n",
      " [[ 0.48840224]]\n",
      "\n",
      " [[ 0.29288651]]\n",
      "\n",
      " [[ 0.33059504]]\n",
      "\n",
      " [[ 0.27367178]]\n",
      "\n",
      " [[ 0.18859941]]\n",
      "\n",
      " [[ 0.26188379]]\n",
      "\n",
      " [[ 0.20851822]]\n",
      "\n",
      " [[ 0.09404346]]\n",
      "\n",
      " [[ 0.05304334]]\n",
      "\n",
      " [[ 0.00832319]]\n",
      "\n",
      " [[ 0.01960969]]\n",
      "\n",
      " [[ 0.04344707]]\n",
      "\n",
      " [[ 0.00298287]]\n",
      "\n",
      " [[ 0.00528365]]\n",
      "\n",
      " [[ 0.06543947]]\n",
      "\n",
      " [[ 0.10788302]]\n",
      "\n",
      " [[ 0.10425373]]\n",
      "\n",
      " [[ 0.17915513]]\n",
      "\n",
      " [[ 0.20450718]]\n",
      "\n",
      " [[ 0.07062174]]\n",
      "\n",
      " [[ 0.05351866]]\n",
      "\n",
      " [[-0.02605527]]\n",
      "\n",
      " [[ 0.02545186]]\n",
      "\n",
      " [[ 0.063716  ]]\n",
      "\n",
      " [[ 0.05769011]]\n",
      "\n",
      " [[-0.06257197]]\n",
      "\n",
      " [[-0.05096795]]\n",
      "\n",
      " [[-0.0979749 ]]\n",
      "\n",
      " [[-0.13473005]]\n",
      "\n",
      " [[-0.06003427]]\n",
      "\n",
      " [[-0.13760684]]\n",
      "\n",
      " [[-0.22434766]]\n",
      "\n",
      " [[-0.15885791]]\n",
      "\n",
      " [[-0.19586512]]\n",
      "\n",
      " [[-0.19926439]]\n",
      "\n",
      " [[-0.06158018]]\n",
      "\n",
      " [[-0.09699205]]\n",
      "\n",
      " [[-0.07359185]]\n",
      "\n",
      " [[-0.13981228]]\n",
      "\n",
      " [[-0.13560379]]\n",
      "\n",
      " [[-0.04658077]]\n",
      "\n",
      " [[ 0.11660499]]\n",
      "\n",
      " [[ 0.0489389 ]]\n",
      "\n",
      " [[ 0.04726998]]\n",
      "\n",
      " [[ 0.13377466]]\n",
      "\n",
      " [[ 0.03237837]]\n",
      "\n",
      " [[ 0.06251117]]\n",
      "\n",
      " [[ 0.10521651]]\n",
      "\n",
      " [[ 0.21736969]]\n",
      "\n",
      " [[ 0.21364557]]\n",
      "\n",
      " [[ 0.14878192]]\n",
      "\n",
      " [[ 0.1469981 ]]\n",
      "\n",
      " [[ 0.11089311]]\n",
      "\n",
      " [[ 0.11991765]]\n",
      "\n",
      " [[ 0.0642978 ]]\n",
      "\n",
      " [[ 0.10693524]]\n",
      "\n",
      " [[ 0.14164224]]\n",
      "\n",
      " [[ 0.09769733]]\n",
      "\n",
      " [[ 0.09257999]]\n",
      "\n",
      " [[ 0.21455842]]\n",
      "\n",
      " [[ 0.30953596]]\n",
      "\n",
      " [[ 0.36185784]]\n",
      "\n",
      " [[ 0.31160401]]\n",
      "\n",
      " [[ 0.31318934]]\n",
      "\n",
      " [[ 0.24387022]]\n",
      "\n",
      " [[ 0.20656567]]\n",
      "\n",
      " [[ 0.20140146]]\n",
      "\n",
      " [[ 0.25339707]]\n",
      "\n",
      " [[ 0.26172378]]\n",
      "\n",
      " [[ 0.11244965]]\n",
      "\n",
      " [[ 0.04340816]]\n",
      "\n",
      " [[-0.04502687]]\n",
      "\n",
      " [[-0.00930363]]\n",
      "\n",
      " [[ 0.02820647]]\n",
      "\n",
      " [[ 0.0390279 ]]\n",
      "\n",
      " [[ 0.0281395 ]]\n",
      "\n",
      " [[ 0.08325014]]\n",
      "\n",
      " [[ 0.01483788]]\n",
      "\n",
      " [[ 0.05138925]]\n",
      "\n",
      " [[ 0.12675127]]\n",
      "\n",
      " [[ 0.18654803]]\n",
      "\n",
      " [[ 0.31983245]]\n",
      "\n",
      " [[ 0.30263019]]\n",
      "\n",
      " [[ 0.24600933]]\n",
      "\n",
      " [[ 0.20525659]]\n",
      "\n",
      " [[ 0.23728223]]\n",
      "\n",
      " [[ 0.20411991]]\n",
      "\n",
      " [[ 0.16941254]]\n",
      "\n",
      " [[ 0.02407865]]\n",
      "\n",
      " [[-0.05352075]]\n",
      "\n",
      " [[-0.16843883]]\n",
      "\n",
      " [[-0.10634452]]\n",
      "\n",
      " [[-0.10697347]]\n",
      "\n",
      " [[-0.00764293]]\n",
      "\n",
      " [[ 0.13048228]]\n",
      "\n",
      " [[ 0.08080822]]\n",
      "\n",
      " [[ 0.0438163 ]]\n",
      "\n",
      " [[ 0.12970083]]\n",
      "\n",
      " [[ 0.26105302]]\n",
      "\n",
      " [[ 0.28187919]]\n",
      "\n",
      " [[ 0.41635259]]\n",
      "\n",
      " [[ 0.23298078]]\n",
      "\n",
      " [[ 0.2430349 ]]\n",
      "\n",
      " [[ 0.28037502]]\n",
      "\n",
      " [[ 0.23673101]]\n",
      "\n",
      " [[ 0.28908662]]\n",
      "\n",
      " [[ 0.25712374]]\n",
      "\n",
      " [[ 0.23058864]]\n",
      "\n",
      " [[ 0.31655514]]\n",
      "\n",
      " [[ 0.34615623]]\n",
      "\n",
      " [[ 0.35613609]]\n",
      "\n",
      " [[ 0.45252586]]\n",
      "\n",
      " [[ 0.41486401]]\n",
      "\n",
      " [[ 0.45146727]]\n",
      "\n",
      " [[ 0.70750265]]\n",
      "\n",
      " [[ 0.59848003]]\n",
      "\n",
      " [[ 0.50020467]]\n",
      "\n",
      " [[ 0.50770659]]\n",
      "\n",
      " [[ 0.5427256 ]]\n",
      "\n",
      " [[ 0.48694373]]\n",
      "\n",
      " [[ 0.46796882]]\n",
      "\n",
      " [[ 0.51474265]]\n",
      "\n",
      " [[ 0.65746333]]\n",
      "\n",
      " [[ 0.40405836]]\n",
      "\n",
      " [[ 0.1395797 ]]\n",
      "\n",
      " [[ 0.09630267]]\n",
      "\n",
      " [[ 0.12039563]]\n",
      "\n",
      " [[ 0.04773382]]\n",
      "\n",
      " [[-0.21368032]]\n",
      "\n",
      " [[-0.13208014]]\n",
      "\n",
      " [[-0.17498779]]\n",
      "\n",
      " [[-0.22399613]]\n",
      "\n",
      " [[-0.18375846]]\n",
      "\n",
      " [[-0.18903951]]\n",
      "\n",
      " [[-0.24317041]]\n",
      "\n",
      " [[-0.17485582]]\n",
      "\n",
      " [[-0.24596651]]]\n"
     ]
    }
   ],
   "source": [
    "window_len = 10 #決定模型要獲取幾天前的數據，隨意選擇\n",
    "norm_cols = ['LAST','VOLUME']\n",
    "LSTM_training_inputs = create_input_data(training_set,10)\n",
    "LSTM_test_inputs = create_input_data(test_set,10)\n",
    "LSTM_training_outputs = create_output_data(training_set,10)\n",
    "LSTM_training_outputs=LSTM_training_outputs[:,np.newaxis,np.newaxis]\n",
    "print(LSTM_training_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAST</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CLOSE_OFF_HIGH</th>\n",
       "      <th>VOLATILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.862872</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.033757</td>\n",
       "      <td>0.880509</td>\n",
       "      <td>-0.679045</td>\n",
       "      <td>0.045317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.054717</td>\n",
       "      <td>2.050791</td>\n",
       "      <td>-0.242054</td>\n",
       "      <td>0.040120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.073856</td>\n",
       "      <td>0.976773</td>\n",
       "      <td>-0.849057</td>\n",
       "      <td>0.025518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.178966</td>\n",
       "      <td>6.513362</td>\n",
       "      <td>-0.816901</td>\n",
       "      <td>0.099767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.038061</td>\n",
       "      <td>11.763117</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.314032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-0.070463</td>\n",
       "      <td>7.030083</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.171409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>-0.060531</td>\n",
       "      <td>4.683923</td>\n",
       "      <td>-0.937767</td>\n",
       "      <td>0.105767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>-0.052462</td>\n",
       "      <td>3.298447</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>0.058518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>-0.065797</td>\n",
       "      <td>1.320834</td>\n",
       "      <td>-0.343405</td>\n",
       "      <td>0.046179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LAST     VOLUME  CLOSE_OFF_HIGH  VOLATILITY\n",
       "452  0.000000   0.000000       -0.862872    0.023982\n",
       "451  0.033757   0.880509       -0.679045    0.045317\n",
       "450  0.054717   2.050791       -0.242054    0.040120\n",
       "449  0.073856   0.976773       -0.849057    0.025518\n",
       "448  0.178966   6.513362       -0.816901    0.099767\n",
       "447  0.038061  11.763117        0.031693    0.314032\n",
       "446 -0.070463   7.030083        0.642857    0.171409\n",
       "445 -0.060531   4.683923       -0.937767    0.105767\n",
       "444 -0.052462   3.298447        0.033582    0.058518\n",
       "443 -0.065797   1.320834       -0.343405    0.046179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_training_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346, 10, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#以 np array的形式做處理，當存以數字的形式\n",
    "LSTM_training_inputs = data_to_np(LSTM_training_inputs)\n",
    "LSTM_test_inputs = data_to_np(LSTM_test_inputs)\n",
    "LSTM_training_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [865,16] vs. shape[1] = [346,16]\n\t [[Node: LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](LSTM_cell/rnn/while/TensorArrayReadV3, LSTM_cell/rnn/while/Identity_3, LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat/axis)]]\n\nCaused by op 'LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat', defined at:\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-93d62da61ed2>\", line 62, in <module>\n    model=LSTMRNN(INPUTSIZE,OUTPUTSIZE,BATCHSIZE,TIMESTEP,CELL_SIZE)\n  File \"<ipython-input-10-93d62da61ed2>\", line 22, in __init__\n    self.add_cell()\n  File \"<ipython-input-10-93d62da61ed2>\", line 42, in add_cell\n    self.cell_outputs,self.cell_final_state=tf.nn.dynamic_rnn(lstm_cell,self.l_in_y,initial_state=self.cell_initial_state,time_major=False)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 574, in dynamic_rnn\n    dtype=dtype)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 737, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 722, in _time_step\n    (output, new_state) = call_cell()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 708, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 180, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 383, in call\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1021, in _linear\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1048, in concat\n    name=name)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 495, in _concat_v2\n    name=name)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [865,16] vs. shape[1] = [346,16]\n\t [[Node: LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](LSTM_cell/rnn/while/TensorArrayReadV3, LSTM_cell/rnn/while/Identity_3, LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [865,16] vs. shape[1] = [346,16]\n\t [[Node: LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](LSTM_cell/rnn/while/TensorArrayReadV3, LSTM_cell/rnn/while/Identity_3, LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-93d62da61ed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLSTM_training_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLSTM_training_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell_initial_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell_final_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cost: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [865,16] vs. shape[1] = [346,16]\n\t [[Node: LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](LSTM_cell/rnn/while/TensorArrayReadV3, LSTM_cell/rnn/while/Identity_3, LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat/axis)]]\n\nCaused by op 'LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat', defined at:\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-93d62da61ed2>\", line 62, in <module>\n    model=LSTMRNN(INPUTSIZE,OUTPUTSIZE,BATCHSIZE,TIMESTEP,CELL_SIZE)\n  File \"<ipython-input-10-93d62da61ed2>\", line 22, in __init__\n    self.add_cell()\n  File \"<ipython-input-10-93d62da61ed2>\", line 42, in add_cell\n    self.cell_outputs,self.cell_final_state=tf.nn.dynamic_rnn(lstm_cell,self.l_in_y,initial_state=self.cell_initial_state,time_major=False)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 574, in dynamic_rnn\n    dtype=dtype)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 737, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2770, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2599, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2549, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 722, in _time_step\n    (output, new_state) = call_cell()\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\", line 708, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 180, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 441, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 383, in call\n    concat = _linear([inputs, h], 4 * self._num_units, True)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\", line 1021, in _linear\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1048, in concat\n    name=name)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 495, in _concat_v2\n    name=name)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [865,16] vs. shape[1] = [346,16]\n\t [[Node: LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](LSTM_cell/rnn/while/TensorArrayReadV3, LSTM_cell/rnn/while/Identity_3, LSTM_cell/rnn/while/rnn/basic_lstm_cell/basic_lstm_cell/concat/axis)]]\n"
     ]
    }
   ],
   "source": [
    "BATCHSIZE=len(LSTM_training_inputs)\n",
    "INPUTSIZE=4\n",
    "OUTPUTSIZE=1\n",
    "TIMESTEP=10\n",
    "CELL_SIZE=16\n",
    "LR=0.1\n",
    "\n",
    "\n",
    "class LSTMRNN(object):\n",
    "    def __init__(self,input_size,output_size,batch_size,n_steps,cell_size):\n",
    "        self.input_size=input_size\n",
    "        self.output_size=output_size\n",
    "        self.batch_size=batch_size\n",
    "        self.n_steps=n_steps\n",
    "        self.cell_size=cell_size\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.xs=tf.placeholder(tf.float32,[None,n_steps,input_size],name=\"xs\")\n",
    "            self.ys=tf.placeholder(tf.float32,[None,1,output_size],name=\"ys\")\n",
    "        with tf.variable_scope('in_hidden'):\n",
    "            self.add_input_layer()\n",
    "        with tf.variable_scope('LSTM_cell'):    \n",
    "            self.add_cell()\n",
    "        with tf.variable_scope('out_hidden'):\n",
    "            self.add_output_layer()\n",
    "        with tf.name_scope('cost'):\n",
    "            self.compute_cost()\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_op=tf.train.AdamOptimizer(LR).minimize(self.loss)\n",
    "            \n",
    "    def add_input_layer(self):\n",
    "        l_in_x=tf.reshape(self.xs,[-1,self.input_size],name=\"2_2D\")\n",
    "        W_in=self.Weight_variable([self.input_size,self.cell_size])\n",
    "        B_in=self.Biases_variable([self.cell_size])\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            l_in_y=tf.matmul(l_in_x,W_in)+B_in\n",
    "        self.l_in_y=tf.reshape(l_in_y,[-1,self.input_size,self.cell_size],name='2_3D')\n",
    "        \n",
    "    def add_cell(self):\n",
    "        lstm_cell=tf.contrib.rnn.BasicLSTMCell(self.cell_size,forget_bias=1,state_is_tuple=True)\n",
    "        with tf.name_scope('initial_state'):\n",
    "            self.cell_initial_state=lstm_cell.zero_state(self.batch_size,dtype=tf.float32)\n",
    "        self.cell_outputs,self.cell_final_state=tf.nn.dynamic_rnn(lstm_cell,self.l_in_y,initial_state=self.cell_initial_state,time_major=False)\n",
    "        \n",
    "    def add_output_layer(self):        \n",
    "        l_out_x=tf.reshape(self.cell_outputs,[-1,self.cell_size],name=\"2_2d\")\n",
    "        W_out=self.Weight_variable([self.cell_size,self.output_size])\n",
    "        B_out=self.Biases_variable([self.output_size])\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            self.pred=tf.matmul(l_out_x,W_out)+B_out\n",
    "        \n",
    "        \n",
    "    def Weight_variable(self,shape,name=\"weight\"):\n",
    "        initializer=tf.random_normal_initializer(mean=0,stddev=1)\n",
    "        return tf.get_variable(shape=shape,initializer=initializer,name=name)\n",
    "    def Biases_variable(self,shape,name='biases'):\n",
    "        initializer=tf.constant_initializer(0.1)\n",
    "        return tf.get_variable(shape=shape,initializer=initializer,name=name)\n",
    "        \n",
    "    def compute_cost(self):\n",
    "        self.loss=tf.reduce_mean(tf.square(tf.reshape(self.pred,[- 1,4])[:,1]-tf.reshape(self.ys, [-1])))\n",
    "        \n",
    "model=LSTMRNN(INPUTSIZE,OUTPUTSIZE,BATCHSIZE,TIMESTEP,CELL_SIZE)\n",
    "sess=tf.Session()\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    if i==0:\n",
    "        feed_dict={model.xs:LSTM_training_inputs,model.ys:LSTM_training_outputs}\n",
    "    else:\n",
    "        feed_dict={xs:LSTM_training_inputs,model.ys:LSTM_training_outputs,model.cell_initial_state:state}\n",
    "\n",
    "    _, cost, state, pred=sess.run([model.train_op, model.loss, model.cell_final_state, model.pred],feed_dict=feed_dict)\n",
    "    if i % 20 == 0:\n",
    "            print('cost: ', round(cost, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
